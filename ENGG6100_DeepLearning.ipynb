{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Tutorial with CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard Python libraries\n",
    "import os # for making os system calls, eg interfacing with unix 'ls' or 'mkdir'\n",
    "import time # useful for approximate benchmarking\n",
    "from tqdm import tqdm # progress bard\n",
    "import numpy as np # numerical library for efficiently manipulating vectors and matrices outside of TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiable programming, Deep Learning frameworks/libraries\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, what is a convolutional neural network? What do we mean by convolution? We technically \n",
    "mean *cross-correlation*, because we don't reverse the filter when dotting with the input window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically use 4-D tensors, with shape `[batch_size, height, width, channels]`, also known as the `NHWC` format. Modern GPUs typically run somewhat faster if you use the `NCHW` format (e.g 30% faster), but we ignore this for now since this is an introductory tutorial. $n_f$ is a variable number of filters set by `nb_filters` in the code below.\n",
    "\n",
    "| Layer         |  H  |  W  |  Channels in   | Channels out | Stride | Padding | Output shape |\n",
    "| ------------- |:---:|:---:|:--------------:|:------------:|:------:|--------:|:-------------|\n",
    "| input         |  32 |  32 |       3        |     1        |   n/a  |  n/a    | ?, 32, 32, 3 |\n",
    "| conv_1        |  8  |  8  |       3        |     $n_f$    |    2   | SAME    | ?, 16, 16, $n_f$ |\n",
    "| conv_2        |  6  |  6  |     $n_f$      |$2 \\times n_f$|    2   | VALID   | ?, 6, 6, $2 \\times n_f$ |\n",
    "| conv_3        |  5  |  5  | $2 \\times n_f$ |$2 \\times n_f$|    1   | VALID   | ?, 2, 2, $2 \\times n_f$ |\n",
    "| fc_out        |  1  |  1  | $8 \\times n_f$ |      10      |    1   | n/a     | ?, 10 |\n",
    "\n",
    "### Notes on padding\n",
    "\n",
    "First, you will notice in the code below that `strides=[1, X, X, 1]`. We generally stride by one unit along each\n",
    "input channel and for each input, which is why `strides[0]` and `strides[3]` are usually 1. We take the value in the \"Stride\" column as `X` in the length 4 strides vector.\n",
    "\n",
    "#### `SAME` padding:\n",
    "\n",
    "-    `out_height = ceil(float(in_height) / float(strides[1]))` = `ceil(float(32) / float(2))` = `ceil(16)` = $16$\n",
    "-    `out_width  = ceil(float(in_width) / float(strides[2]))` = \" = $16$\n",
    "\n",
    "Now, given that we know the output dimensionality has `(height, width)` = ($16$,$16$), how much padding was used?\n",
    "\n",
    "$$ ceil( \\frac{n_i + p_i - k + 1}{s} )  = n_o $$\n",
    "\n",
    "In general, ceil( $\\frac{x}{a}$ ) = $b$ with $a > 0$ means $b - 1 < \\frac{x}{a} \\leq b$, the smallest integer that satisfies this is $x = a(b-1) + 1$.\n",
    "\n",
    "$$ n_i + p_i - k + 1 = s (n_o - 1) + 1 $$\n",
    "\n",
    "$$ p_i = s (n_o - 1) + k - n_i $$\n",
    "\n",
    "$$ p_i = 2 (16 - 1) + 8 - 32 = 30 + 8 - 32 = 6 $$\n",
    "\n",
    "#### `VALID` padding:\n",
    "\n",
    "- `out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))` = `ceil((16 - 6 + 1) / 2))` = `ceil(5.5)` = $6$\n",
    "- `out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))` = \" = $6$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet:\n",
    "    \n",
    "    def __init__(self, x, nb_filters, use_batch_norm, phase, reuse):\n",
    "        self.__dict__.update(locals())\n",
    "        self.convolutional_layers(use_batch_norm, phase)\n",
    "        # calculate the number of parameters to be learned in our model\n",
    "        self.nb_params = np.sum([np.prod(v.shape) for v in tf.trainable_variables()])\n",
    "        print(\"Created instance of CNN model with %d parameters\" % self.nb_params)\n",
    "    \n",
    "    def initialize_kernel(self, shape, stddev=0.1):\n",
    "        init = tf.truncated_normal(shape, stddev=stddev, dtype=tf.float32)\n",
    "        init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=(0, 1, 2)))\n",
    "        return tf.Variable(init)\n",
    "    \n",
    "    def get_kernel(self, shape, stddev=0.1):\n",
    "        init = tf.truncated_normal(shape, stddev=stddev, dtype=tf.float32)\n",
    "        init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=(0, 1, 2)))\n",
    "        return tf.get_variable(\"k\", initializer=init)\n",
    "    \n",
    "    def initialize_weight(self, shape, stddev=0.1):\n",
    "        init = tf.truncated_normal(shape, stddev=stddev, dtype=tf.float32)\n",
    "        init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=0, keep_dims=True))\n",
    "        return tf.Variable(init)\n",
    "    \n",
    "    def get_weight(self, shape, stddev=0.1):\n",
    "        init = tf.truncated_normal(shape, stddev=stddev, dtype=tf.float32)\n",
    "        init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=0, keep_dims=True))\n",
    "        return tf.get_variable(\"w\", initializer=init)\n",
    "    \n",
    "    def bias_variable(self, shape):\n",
    "        init = tf.constant(0, shape=shape)\n",
    "        return tf.Variable(init)\n",
    "    \n",
    "    def conv2d(self, x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "    def max_pool_2x2(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                              strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    def convolutional_layers(self, use_batch_norm, phase):\n",
    "\n",
    "        pad_k = tf.constant([[1, 1], [1, 1], [0, 0]])\n",
    "        pad_a = tf.constant([[0, 0], [1, 1], [1, 1]])\n",
    "\n",
    "        with tf.name_scope('conv_1') as scope:\n",
    "\n",
    "            k_sz = 8 # the square kernel size (e.g 8x8)\n",
    "            \n",
    "            #W_conv1 = self.initialize_kernel([k_sz, k_sz, int(self.x.shape[3]), self.nb_filters])\n",
    "            '''\n",
    "            Try un-commmenting the above line in all layers and observing the number\n",
    "            of parameters change everytime you run the below cell titled\n",
    "            \"Instantiate the CNN model\". If we don't explicitly tell TensorFlow to re-use \n",
    "            variables, additional copies of the graph will be created, blowing up the \n",
    "            number of parameters. Reusing variables is accomplished by creating them under\n",
    "            a tf.variable_scope, and using tf.get_variable rather than tf.Variable.\n",
    "            If you want to force a new variable to be created everytime, you can\n",
    "            set reuse=False.\n",
    "            '''\n",
    "            with tf.variable_scope('conv_1_init', reuse=self.reuse):\n",
    "                W_conv1 = self.get_kernel([k_sz, k_sz, int(self.x.shape[3]), self.nb_filters])\n",
    "                \n",
    "            '''\n",
    "            for logging to Tensorboard \"Images\" tab. \n",
    "            This is a bit of a hack to combine all 8x8 convolution\n",
    "            filters into one image.\n",
    "            '''\n",
    "            W1_c = tf.split(W_conv1, self.nb_filters, 3)  # nb_filters x [8, 8, 3, 1]\n",
    "            for i in range(self.nb_filters):\n",
    "                W1_c[i] = tf.pad(tf.reshape(\n",
    "                    W1_c[i], [k_sz, k_sz, int(self.x.shape[3])]), pad_k, \"CONSTANT\")\n",
    "            W1_row0 = tf.concat(W1_c[0:8], 0)      # [80, 10, 3, 1]\n",
    "            W1_row1 = tf.concat(W1_c[8:16], 0)     # [80, 10, 3, 1]\n",
    "            W1_row2 = tf.concat(W1_c[16:24], 0)    # [80, 10, 3, 1]\n",
    "            W1_row3 = tf.concat(W1_c[24:32], 0)    # [80, 10, 3, 1]\n",
    "            W1_row4 = tf.concat(W1_c[32:40], 0)    # [80, 10, 3, 1]\n",
    "            W1_row5 = tf.concat(W1_c[40:48], 0)    # [80, 10, 3, 1]\n",
    "            W1_row6 = tf.concat(W1_c[48:56], 0)    # [80, 10, 3, 1]\n",
    "            W1_row7 = tf.concat(W1_c[56:64], 0)    # [80, 10, 3, 1]\n",
    "            W1_d = tf.concat([W1_row0, W1_row1, W1_row2, W1_row3, W1_row4,\n",
    "                              W1_row5, W1_row6, W1_row7], 1)  # [80, 80, 3, 1]\n",
    "            W1_e = tf.reshape(W1_d, [1, 80, 80, int(self.x.shape[3])])\n",
    "            \n",
    "            # Create the actual summary to appear in Tensorboard\n",
    "            tf.summary.image(\"k1\", W1_e, 1)\n",
    "\n",
    "            # Create tensors for L1 and L2 weight decay\n",
    "            self.W_conv1_p = tf.nn.l2_loss(W_conv1)\n",
    "            self.W_conv1_l1 = tf.reduce_mean(tf.abs(W_conv1))\n",
    "            \n",
    "            h_conv1 = tf.nn.relu(tf.nn.conv2d(\n",
    "                self.x, W_conv1, strides=[1, 2, 2, 1], padding='SAME'))\n",
    "\n",
    "            a1_u, a1_var = tf.nn.moments(\n",
    "                tf.abs(h_conv1), axes=[0], keep_dims=False)\n",
    "\n",
    "            tf.summary.histogram(name='h_conv1_summ', values=h_conv1)\n",
    "            tf.summary.histogram(name='W_conv1_summ', values=W_conv1)\n",
    "            tf.summary.scalar(\"activation_mean\", tf.reduce_mean(a1_u))\n",
    "            tf.summary.scalar(\"activation_variance\", tf.reduce_mean(a1_var))\n",
    "\n",
    "        with tf.name_scope('conv_2') as scope:\n",
    "\n",
    "            k_sz = 6 # the square kernel size\n",
    "            in_ch = self.nb_filters\n",
    "            out_ch = self.nb_filters * 2\n",
    "            \n",
    "            #self.W_conv2 = self.initialize_kernel([k_sz, k_sz, in_ch, out_ch])\n",
    "            with tf.variable_scope('conv_2_init', reuse=self.reuse):\n",
    "                self.W_conv2 = self.get_kernel([k_sz, k_sz, in_ch, out_ch])\n",
    "            \n",
    "            # Create tensors for L1 and L2 weight decay\n",
    "            self.W_conv2_p = tf.nn.l2_loss(self.W_conv2)\n",
    "            self.W_conv2_l1 = tf.reduce_mean(tf.abs(self.W_conv2))\n",
    "\n",
    "            if self.use_batch_norm:\n",
    "                # see https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm\n",
    "                # for full list of default settings.\n",
    "                with tf.variable_scope('conv_2_bn', reuse=self.reuse):\n",
    "                    h_conv1 = tf.contrib.layers.batch_norm(h_conv1, is_training=phase)\n",
    "\n",
    "            W2_c = tf.split(self.W_conv2, self.nb_filters * 2,\n",
    "                            3)  # f_out x [6, 6, f_in, 1]\n",
    "            for i in range(self.nb_filters):\n",
    "                W2_c[i] = tf.pad(tf.reshape(\n",
    "                    W2_c[i], [k_sz, k_sz, self.nb_filters]), pad_k, \"CONSTANT\")\n",
    "            W2_row0 = tf.concat(W2_c[0:8], 0)      # [64, 8, f_in, 1]\n",
    "            W2_row1 = tf.concat(W2_c[8:16], 0)     # [64, 8, f_in, 1]\n",
    "            W2_row2 = tf.concat(W2_c[16:24], 0)    # [64, 8, f_in, 1]\n",
    "            W2_row3 = tf.concat(W2_c[24:32], 0)    # [64, 8, f_in, 1]\n",
    "            W2_row4 = tf.concat(W2_c[32:40], 0)    # [64, 8, f_in, 1]\n",
    "            W2_row5 = tf.concat(W2_c[40:48], 0)    # [64, 8, f_in, 1]\n",
    "            W2_row6 = tf.concat(W2_c[48:56], 0)    # [64, 8, f_in, 1]\n",
    "            W2_row7 = tf.concat(W2_c[56:64], 0)    # [64, 8, f_in, 1]\n",
    "            W2_d = tf.concat([W2_row0, W2_row1, W2_row2, W2_row3, W2_row4,\n",
    "                              W2_row5, W2_row6, W2_row7], 1)  # [64, 64, 3, 1]\n",
    "            W2_e = tf.reshape(W2_d, [1, 64, 64, self.nb_filters])\n",
    "            W2_f = tf.split(W2_e, self.nb_filters, 3)  # 64 x [1, 64, 64, 1]\n",
    "            W2_g = tf.concat(W2_f[0:self.nb_filters], 0)\n",
    "            \n",
    "            # Create the summary to appear in Tensorboard\n",
    "            tf.summary.image(\"k2\", W2_g, 4)\n",
    "\n",
    "            h_conv2 = tf.nn.relu(tf.nn.conv2d(\n",
    "                h_conv1, self.W_conv2, strides=[1, 2, 2, 1], padding='VALID'))\n",
    "\n",
    "            a2_u, a2_var = tf.nn.moments(\n",
    "                tf.abs(h_conv2), axes=[0], keep_dims=False)\n",
    "\n",
    "            tf.summary.histogram(name='W_conv2_summ', values=self.W_conv2)\n",
    "            tf.summary.histogram(name='h_conv2_summ', values=h_conv2)\n",
    "            tf.summary.scalar(\"activation_mean\", tf.reduce_mean(a2_u))\n",
    "            tf.summary.scalar(\"activation_variance\", tf.reduce_mean(a2_var))\n",
    "            \n",
    "        with tf.name_scope('conv_3') as scope:\n",
    "        \n",
    "            k_sz = 5 # the square kernel size\n",
    "            in_ch = self.nb_filters * 2\n",
    "            out_ch = self.nb_filters * 2\n",
    "            \n",
    "            #self.W_conv3 = self.initialize_kernel([k_sz, k_sz, in_ch, out_ch])\n",
    "            with tf.variable_scope('conv_3_init', reuse=self.reuse):\n",
    "                self.W_conv3 = self.get_kernel([k_sz, k_sz, in_ch, out_ch])\n",
    "            \n",
    "            # weight decay\n",
    "            self.W_conv3_p = tf.nn.l2_loss(self.W_conv3)\n",
    "            self.W_conv3_l1 = tf.reduce_mean(tf.abs(self.W_conv3))\n",
    "    \n",
    "            if self.use_batch_norm:\n",
    "                with tf.variable_scope('conv_3_bn', reuse=self.reuse):\n",
    "                    h_conv2 = tf.contrib.layers.batch_norm(h_conv2, is_training=phase)\n",
    "\n",
    "            h_conv3 = tf.nn.relu(tf.nn.conv2d(\n",
    "                h_conv2, self.W_conv3, strides=[1, 1, 1, 1], padding='VALID'))\n",
    "\n",
    "            a3_u, a3_var = tf.nn.moments(\n",
    "                tf.abs(h_conv3), axes=[0], keep_dims=False)\n",
    "\n",
    "            tf.summary.histogram(name='W_conv3_summ', values=self.W_conv3)\n",
    "            tf.summary.histogram(name='h_conv3_summ', values=h_conv3)\n",
    "            tf.summary.scalar(\"activation_mean\", tf.reduce_mean(a3_u))\n",
    "            tf.summary.scalar(\"activation_variance\", tf.reduce_mean(a3_var))\n",
    "            \n",
    "        with tf.name_scope('fc_out') as scope:\n",
    "\n",
    "            nb_classes = 10\n",
    "            in_sz = self.nb_filters * 8\n",
    "            \n",
    "            #W_fcout = self.initialize_weight([in_sz, nb_classes])\n",
    "            with tf.variable_scope('fc_out_init', reuse=self.reuse):\n",
    "                W_fcout = self.get_weight([in_sz, nb_classes])\n",
    "            \n",
    "            # weight decay\n",
    "            self.W_fcout_p = tf.nn.l2_loss(W_fcout)\n",
    "            self.W_fcout_l1 = tf.reduce_mean(tf.abs(W_fcout))\n",
    "\n",
    "            h_conv3_flat = tf.reshape(h_conv3, [-1, in_sz])\n",
    "            \n",
    "            # tensor equivalent of numpy.dot()\n",
    "            self.output = tf.matmul(h_conv3_flat, W_fcout) \n",
    "\n",
    "            y_u, y_var = tf.nn.moments(\n",
    "                tf.abs(self.output), axes=[0], keep_dims=False)\n",
    "\n",
    "            norm_out = tf.norm(W_fcout)\n",
    "            \n",
    "            tf.summary.histogram(name='output_summ', values=self.output)\n",
    "            tf.summary.scalar(\"norm_out\", norm_out)\n",
    "            tf.summary.scalar(\"logits_mean\", tf.reduce_mean(y_u))\n",
    "            tf.summary.scalar(\"logits_var\", tf.reduce_mean(y_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method for loading and preprocessing the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cifar10():\n",
    "    \"\"\"\n",
    "    Preprocess CIFAR-10 dataset\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # These values are specific to CIFAR-10\n",
    "    img_rows = 32\n",
    "    img_cols = 32\n",
    "    nb_classes = 10\n",
    "\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = data_cifar10()\n",
    "__, img_rows, img_cols, channels = train_x.shape\n",
    "__, nb_classes = train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some variables and placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to keep track of how many steps we've trained our model for\n",
    "tf.reset_default_graph()\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "dtype = tf.float32\n",
    "x_ = tf.placeholder(dtype, shape=(None, img_rows, img_cols, channels))\n",
    "y_ = tf.placeholder(dtype, shape=(None, nb_classes))\n",
    "\n",
    "# This is for batch normalization. True means training mode, False means testing mode.\n",
    "phase = tf.placeholder_with_default(True, shape=(), name='phase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_save_path(root_path, batch_size, nb_filters, learning_rate, epochs):\n",
    "    \n",
    "    model_path = os.path.join(root_path, 'k_' + str(nb_filters))\n",
    "    model_path = os.path.join(model_path, 'bs_' + str(batch_size))\n",
    "    model_path = os.path.join(model_path, 'lr_%1.e' % learning_rate)\n",
    "    model_path = os.path.join(model_path, 'ep_' + str(epochs))\n",
    "    '''\n",
    "    optionally create this folder if it does not already exist,\n",
    "    otherwise, increment the subfolder number\n",
    "    '''\n",
    "    model_path = create_dir_if_not_exists(model_path)\n",
    "\n",
    "    return model_path\n",
    "\n",
    "\n",
    "def create_dir_if_not_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        path += '/1'\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        digits = []\n",
    "        sub_dirs = next(os.walk(path))[1]\n",
    "        [digits.append(s) for s in sub_dirs if s.isnumeric()]\n",
    "        if len(digits) > 0:\n",
    "            sub = str(np.max(np.asarray(sub_dirs).astype('uint8')) + 1)        \n",
    "        else:\n",
    "            sub = '1'\n",
    "        path = os.path.join(path, sub)\n",
    "        os.makedirs(path)\n",
    "    print('Logging to:%s' % path)\n",
    "    return path\n",
    "\n",
    "\n",
    "def batch_indices(batch_nb, data_length, batch_size):\n",
    "    \"\"\"\n",
    "    This helper function computes a batch start and end index\n",
    "    :param batch_nb: the batch number\n",
    "    :param data_length: the total length of the data being parsed by batches\n",
    "    :param batch_size: the number of inputs in each batch\n",
    "    :return: pair of (start, end) indices\n",
    "    \"\"\"\n",
    "    # Batch start and end index\n",
    "    start = int(batch_nb * batch_size)\n",
    "    end = int((batch_nb + 1) * batch_size)\n",
    "\n",
    "    # When there are not enough inputs left, we reuse some to complete the\n",
    "    # batch\n",
    "    if end > data_length:\n",
    "        shift = end - data_length\n",
    "        start -= shift\n",
    "        end -= shift\n",
    "\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = 1e-3\n",
    "l1_reg = 1e-3\n",
    "nb_epochs = 25\n",
    "nb_filters = 64\n",
    "batch_size = 128 # normally use 128\n",
    "learning_rate = 1e-3\n",
    "batch_norm = False\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to:/scratch/ssd/logs/cifar10/k_64/bs_128/lr_1e-03/ep_25/1\n"
     ]
    }
   ],
   "source": [
    "model_path = '/scratch/ssd/logs/cifar10'\n",
    "\n",
    "# assume we're going to train from scratch, and not log checkpoints\n",
    "save = False\n",
    "train_from_scratch = True\n",
    "\n",
    "if model_path is not None:\n",
    "    if os.path.exists(model_path):\n",
    "        # check for existing model in immediate subfolder\n",
    "        if any(f.endswith('.meta') for f in os.listdir(model_path)):\n",
    "            train_from_scratch = False\n",
    "        else:\n",
    "            save = True\n",
    "            model_path = build_model_save_path(\n",
    "                model_path, batch_size, nb_filters, learning_rate, nb_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the CNN model\n",
    "\n",
    "With the default settings and when reusing variables, we should get $721,920$ parameters \n",
    "if `batch_norm=False`, and $721,920 + 192 = 722,112$ parameters if `batch_norm=True`.\n",
    "Options for the reuse argument are `False`, `True`, and `tf.AUTO_REUSE`. The call will\n",
    "fail if you set `reuse=True` the first time you run the below cell, since the variables\n",
    "have not yet been created. The call will fail on subsequent calls if you set\n",
    "`reuse=False`, since variables with the same name already exist. This flow generally\n",
    "prevents you from making silly mistakes and enforces the desirable behaviour. `tf.AUTO_REUSE`\n",
    "will always do the right thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created instance of CNN model with 721920 parameters\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(x_, nb_filters, batch_norm, phase, reuse=tf.AUTO_REUSE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = cnn.output\n",
    "\n",
    "total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=y_, logits=logits))\n",
    "\n",
    "# if you just want the model predictions, use the following:\n",
    "# preds = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add weight decay to loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss += l2_reg * (cnn.W_conv1_p + cnn.W_conv2_p +\n",
    "                        cnn.W_conv3_p + cnn.W_fcout_p)\n",
    "\n",
    "total_loss += l1_reg * (cnn.W_conv1_l1 + cnn.W_conv2_l1 +\n",
    "                        cnn.W_conv3_l1 + cnn.W_fcout_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training op, and batch normalization if applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if batch_norm:\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        # ensures that we execute the update_ops before performing the train_op\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "                    total_loss, global_step, learning_rate=learning_rate, optimizer='Adam',  # SGD\n",
    "                    summaries=[\"gradients\"])\n",
    "else:\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "                total_loss, global_step, learning_rate=learning_rate, optimizer='Adam',\n",
    "                summaries=[\"gradients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create tensors that will automatically compute the number of \n",
    "correct predictions and accuracy in a sample\n",
    "'''\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startup time was 35.1317\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.Session()\n",
    "start_time = time.time()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "d = float(time.time() - start_time)\n",
    "print(\"Startup time was %.4f\" % d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup summary writer\n",
    "if save:\n",
    "    summary_writer = tf.summary.FileWriter(model_path, sess.graph)\n",
    "    tf.summary.scalar(\n",
    "                \"stats/train_loss\", total_loss)\n",
    "    tf.summary.scalar(\"stats/train_accuracy\", accuracy)\n",
    "    \n",
    "    # create one op that will run all summaries\n",
    "    merge_op = tf.summary.merge_all()\n",
    "    checkpoint_path = os.path.join(model_path, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sess, tensor, x, y, x_np, y_np, feed=None):\n",
    "    feed_dict = {x: x_np, y: y_np, phase: False}\n",
    "    if feed is not None:\n",
    "        feed_dict.update(feed)\n",
    "    return sess.run(tensor, feed_dict)\n",
    "\n",
    "def evaluate_model(sess, accuracy, x, y, test_x, test_y, batch_size):\n",
    "    \"\"\"\n",
    "    This helper function evaluates a model on one pass through\n",
    "    the test set\n",
    "    :param accuracy: the tensor that computes accuracy\n",
    "    :param x: input placeholder\n",
    "    :param y: output placeholder\n",
    "    :param test_x: the test examples\n",
    "    :param test_y: the test labels\n",
    "    :param batch_size: batch size to use when evaluating\n",
    "    :return: accuracy on the test set\n",
    "    \"\"\"\n",
    "    nb_test_examples = test_x.shape[0]\n",
    "    nb_test_batches = int(\n",
    "        np.ceil(float(nb_test_examples) / batch_size))\n",
    "    # print('nb_test_batches=%d' % nb_test_batches)\n",
    "    assert nb_test_batches * batch_size >= nb_test_examples\n",
    "\n",
    "    tot_accuracy = 0.0\n",
    "    for e, test_batch in enumerate(range(nb_test_batches)):\n",
    "        # Must not use the `batch_indices` function here, because it\n",
    "        # repeats some examples.\n",
    "        # It's acceptable to repeat during training, but not eval.\n",
    "        start = test_batch * batch_size\n",
    "        end = min(nb_test_examples, start + batch_size)\n",
    "        cur_batch_size = end - start\n",
    "        batch_xs = test_x[start:end]\n",
    "        batch_ys = test_y[start:end]\n",
    "        cur_acc = evaluate(sess, accuracy, x,\n",
    "                           y_, batch_xs, batch_ys)\n",
    "        tot_accuracy += (cur_batch_size * cur_acc)\n",
    "    tot_accuracy /= nb_test_examples\n",
    "    return tot_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/391 [00:00<00:55,  7.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_training_batches=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 3/391 [00:00<00:43,  8.88it/s]\u001b[A\n",
      "  1%|          | 4/391 [00:00<00:46,  8.39it/s]\u001b[A\n",
      "  1%|▏         | 5/391 [00:00<00:46,  8.24it/s]\u001b[A\n",
      "  2%|▏         | 6/391 [00:00<00:46,  8.25it/s]\u001b[A\n",
      "  2%|▏         | 7/391 [00:00<00:45,  8.36it/s]\u001b[A\n",
      "  2%|▏         | 8/391 [00:00<00:46,  8.26it/s]\u001b[A\n",
      "  2%|▏         | 9/391 [00:01<00:46,  8.25it/s]\u001b[A\n",
      "  3%|▎         | 10/391 [00:01<00:46,  8.19it/s]\u001b[A\n",
      "  3%|▎         | 11/391 [00:01<00:46,  8.17it/s]\u001b[A\n",
      "  3%|▎         | 13/391 [00:01<00:44,  8.59it/s]\u001b[A\n",
      "  4%|▎         | 14/391 [00:01<00:43,  8.60it/s]\u001b[A\n",
      "  4%|▍         | 15/391 [00:01<00:43,  8.63it/s]\u001b[A\n",
      "  4%|▍         | 16/391 [00:01<00:43,  8.57it/s]\u001b[A\n",
      "  4%|▍         | 17/391 [00:01<00:43,  8.55it/s]\u001b[A\n",
      "  5%|▍         | 18/391 [00:02<00:43,  8.62it/s]\u001b[A\n",
      "  5%|▌         | 20/391 [00:02<00:42,  8.80it/s]\u001b[A\n",
      "  5%|▌         | 21/391 [00:02<00:42,  8.74it/s]\u001b[A\n",
      "  6%|▌         | 22/391 [00:02<00:42,  8.71it/s]\u001b[A\n",
      "  6%|▌         | 23/391 [00:02<00:42,  8.71it/s]\u001b[A\n",
      "  6%|▌         | 24/391 [00:02<00:42,  8.70it/s]\u001b[A\n",
      "  6%|▋         | 25/391 [00:02<00:41,  8.72it/s]\u001b[A\n",
      "  7%|▋         | 26/391 [00:02<00:41,  8.74it/s]\u001b[A\n",
      "  7%|▋         | 27/391 [00:03<00:41,  8.71it/s]\u001b[A\n",
      "  7%|▋         | 28/391 [00:03<00:41,  8.72it/s]\u001b[A\n",
      "  8%|▊         | 30/391 [00:03<00:41,  8.77it/s]\u001b[A\n",
      "  8%|▊         | 31/391 [00:03<00:41,  8.75it/s]\u001b[A\n",
      "  8%|▊         | 32/391 [00:03<00:41,  8.69it/s]\u001b[A\n",
      "  8%|▊         | 33/391 [00:03<00:41,  8.65it/s]\u001b[A\n",
      "  9%|▊         | 34/391 [00:03<00:41,  8.65it/s]\u001b[A\n",
      "  9%|▉         | 35/391 [00:04<00:41,  8.66it/s]\u001b[A\n",
      "  9%|▉         | 36/391 [00:04<00:41,  8.61it/s]\u001b[A\n",
      "  9%|▉         | 37/391 [00:04<00:40,  8.64it/s]\u001b[A\n",
      " 10%|▉         | 38/391 [00:04<00:40,  8.64it/s]\u001b[A\n",
      " 10%|▉         | 39/391 [00:04<00:40,  8.62it/s]\u001b[A\n",
      " 10%|█         | 40/391 [00:04<00:40,  8.62it/s]\u001b[A\n",
      " 10%|█         | 41/391 [00:04<00:40,  8.59it/s]\u001b[A\n",
      " 11%|█         | 42/391 [00:04<00:40,  8.56it/s]\u001b[A\n",
      " 11%|█▏        | 44/391 [00:05<00:40,  8.63it/s]\u001b[A\n",
      " 12%|█▏        | 45/391 [00:05<00:40,  8.60it/s]\u001b[A\n",
      " 12%|█▏        | 46/391 [00:05<00:40,  8.58it/s]\u001b[A\n",
      " 12%|█▏        | 47/391 [00:05<00:40,  8.57it/s]\u001b[A\n",
      " 12%|█▏        | 48/391 [00:05<00:40,  8.53it/s]\u001b[A\n",
      " 13%|█▎        | 49/391 [00:05<00:40,  8.49it/s]\u001b[A\n",
      " 13%|█▎        | 51/391 [00:05<00:39,  8.59it/s]\u001b[A\n",
      " 13%|█▎        | 52/391 [00:06<00:39,  8.57it/s]\u001b[A\n",
      " 14%|█▎        | 53/391 [00:06<00:39,  8.53it/s]\u001b[A\n",
      " 14%|█▍        | 54/391 [00:06<00:39,  8.51it/s]\u001b[A\n",
      " 14%|█▍        | 55/391 [00:06<00:39,  8.52it/s]\u001b[A\n",
      " 14%|█▍        | 56/391 [00:06<00:39,  8.50it/s]\u001b[A\n",
      " 15%|█▍        | 57/391 [00:06<00:39,  8.48it/s]\u001b[A\n",
      " 15%|█▍        | 58/391 [00:06<00:39,  8.44it/s]\u001b[A\n",
      " 15%|█▌        | 59/391 [00:07<00:39,  8.38it/s]\u001b[A\n",
      " 15%|█▌        | 60/391 [00:07<00:39,  8.40it/s]\u001b[A\n",
      " 16%|█▌        | 61/391 [00:07<00:39,  8.41it/s]\u001b[A\n",
      " 16%|█▌        | 62/391 [00:07<00:39,  8.41it/s]\u001b[A\n",
      " 16%|█▋        | 64/391 [00:07<00:38,  8.49it/s]\u001b[A\n",
      " 17%|█▋        | 65/391 [00:07<00:38,  8.48it/s]\u001b[A\n",
      " 17%|█▋        | 67/391 [00:07<00:38,  8.51it/s]\u001b[A\n",
      " 17%|█▋        | 68/391 [00:07<00:37,  8.50it/s]\u001b[A\n",
      " 18%|█▊        | 69/391 [00:08<00:38,  8.46it/s]\u001b[A\n",
      " 18%|█▊        | 70/391 [00:08<00:38,  8.44it/s]\u001b[A\n",
      " 18%|█▊        | 71/391 [00:08<00:38,  8.41it/s]\u001b[A\n",
      " 19%|█▊        | 73/391 [00:08<00:37,  8.48it/s]\u001b[A\n",
      " 19%|█▉        | 74/391 [00:08<00:37,  8.48it/s]\u001b[A\n",
      " 19%|█▉        | 75/391 [00:08<00:37,  8.47it/s]\u001b[A\n",
      " 19%|█▉        | 76/391 [00:08<00:37,  8.47it/s]\u001b[A\n",
      " 20%|█▉        | 77/391 [00:09<00:37,  8.49it/s]\u001b[A\n",
      " 20%|█▉        | 78/391 [00:09<00:36,  8.49it/s]\u001b[A\n",
      " 20%|██        | 79/391 [00:09<00:36,  8.49it/s]\u001b[A\n",
      " 20%|██        | 80/391 [00:09<00:36,  8.49it/s]\u001b[A\n",
      " 21%|██        | 81/391 [00:09<00:36,  8.48it/s]\u001b[A\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/export/mlrg/gallowaa/anaconda2/envs/tf140-py35/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/export/mlrg/gallowaa/anaconda2/envs/tf140-py35/lib/python3.5/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/export/mlrg/gallowaa/anaconda2/envs/tf140-py35/lib/python3.5/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 391/391 [00:43<00:00,  9.05it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss=1.5357, test_acc=0.4593 (1074.3 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:39<00:00,  9.88it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss=1.5398, test_acc=0.4922 (1206.1 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:39<00:00,  9.95it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss=1.4089, test_acc=0.5174 (1228.2 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:39<00:00,  9.92it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss=1.3698, test_acc=0.5212 (1243.7 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:36<00:00, 10.69it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss=1.2002, test_acc=0.5820 (1243.1 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:35<00:00, 10.87it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss=1.1874, test_acc=0.5796 (1187.8 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:35<00:00, 11.05it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, loss=1.0481, test_acc=0.5905 (1267.2 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:34<00:00, 11.30it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, loss=1.1238, test_acc=0.6143 (1336.7 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:35<00:00, 11.07it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, loss=0.9510, test_acc=0.6206 (1294.3 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:35<00:00, 11.10it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, loss=1.1053, test_acc=0.6288 (1533.1 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:35<00:00, 11.04it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss=1.1269, test_acc=0.5929 (1506.3 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:35<00:00, 10.96it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, loss=1.2808, test_acc=0.6231 (1342.2 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:34<00:00, 11.26it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, loss=0.9286, test_acc=0.6343 (1894.6 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:35<00:00, 11.11it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, loss=1.0329, test_acc=0.6468 (1147.0 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:36<00:00, 10.86it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, loss=0.9111, test_acc=0.6519 (1249.2 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:36<00:00, 10.62it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, loss=1.0523, test_acc=0.6464 (1813.1 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:36<00:00, 10.73it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, loss=1.1462, test_acc=0.6513 (1215.7 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:35<00:00, 10.87it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, loss=1.0845, test_acc=0.6574 (1167.7 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:33<00:00, 11.53it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, loss=0.8215, test_acc=0.6510 (1250.2 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:34<00:00, 11.37it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, loss=1.0904, test_acc=0.6540 (1956.3 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:33<00:00, 11.54it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, loss=0.8503, test_acc=0.6637 (1831.1 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:35<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, loss=0.9377, test_acc=0.6376 (1653.3 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:34<00:00, 11.28it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, loss=0.8730, test_acc=0.6624 (1570.7 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:35<00:00, 10.97it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, loss=0.9028, test_acc=0.6460 (1341.4 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:33<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, loss=0.9758, test_acc=0.6528 (2169.4 ex/s)\n"
     ]
    }
   ],
   "source": [
    "if train_from_scratch:\n",
    "    step = 0\n",
    "    init_step = 0\n",
    "    max_acc = 0\n",
    "    \n",
    "    # Compute number of training batches\n",
    "    nb_training_examples = train_x.shape[0]\n",
    "    nb_batches = int(\n",
    "    np.ceil(float(nb_training_examples) / batch_size))\n",
    "    print('nb_training_batches=%d' % nb_batches)\n",
    "    assert nb_batches * batch_size >= nb_training_examples\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "\n",
    "        # Indices to shuffle training set\n",
    "        index_shuf = np.arange(nb_training_examples)\n",
    "        np.random.shuffle(index_shuf)\n",
    "\n",
    "        for batch in tqdm(range(nb_batches)):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            step = init_step + (epoch * nb_batches + batch)\n",
    "\n",
    "            # Compute batch start and end indices\n",
    "            start, end = batch_indices(\n",
    "                batch, nb_training_examples, batch_size)\n",
    "\n",
    "            batch_xs = train_x[index_shuf[start:end]]\n",
    "            batch_ys = train_y[index_shuf[start:end]]\n",
    "\n",
    "            __, loss_val, summ = sess.run([train_op, total_loss, merge_op], feed_dict={\n",
    "                x_: batch_xs, y_: batch_ys})\n",
    "            duration = time.time() - start_time\n",
    "            summary_writer.add_summary(summ, global_step=step)\n",
    "        summary_writer.flush()\n",
    "\n",
    "        # Init result var\n",
    "        tot_accuracy = evaluate_model(\n",
    "            sess, accuracy, x_, y_, test_x, test_y, batch_size)       \n",
    "\n",
    "        print(\"epoch %d, loss=%.4f, test_acc=%.4f (%.1f ex/s)\" %\n",
    "              (epoch, loss_val, tot_accuracy, float(batch_size / duration)))\n",
    "\n",
    "        if model_path:\n",
    "            saver.save(sess, checkpoint_path, global_step=step)\n",
    "        step += 1\n",
    "    # close the TensorFlow client session\n",
    "    tf.reset_default_graph()\n",
    "    sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
