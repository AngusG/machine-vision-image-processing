{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Tutorial with CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard Python libraries\n",
    "import os # for making os system calls, eg interfacing with unix 'ls' or 'mkdir'\n",
    "import time # useful for approximate benchmarking\n",
    "from tqdm import tqdm # progress bard\n",
    "import numpy as np # numerical library for efficiently manipulating vectors and matrices outside of TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differentiable programming, Deep Learning frameworks/libraries\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, what is a convolutional neural network? What do we mean by convolution? We technically \n",
    "mean *cross-correlation*, because we don't reverse the filter when dotting with the input window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically use 4-D tensors, with shape `[batch_size, height, width, channels]`, also known as the `NHWC` format. Modern GPUs typically run somewhat faster if you use the `NCHW` format (e.g 30% faster), but we ignore this for now since this is an introductory tutorial. $n_f$ is a variable number of filters set by `nb_filters` in the code below.\n",
    "\n",
    "| Layer         |  H  |  W  |  Channels in   | Channels out | Stride | Padding | Output shape         | Params    | \n",
    "| ------------- |:---:|:---:|:--------------:|:------------:|:------:|--------:|:---------------------|----------:|\n",
    "| input         |  32 |  32 |       3        |     1        |   n/a  |  n/a    |      ?, 32, 32, 3    |  0        |\n",
    "| conv_1        |  8  |  8  |       3        |     $n_f$    |    2   | SAME    | ?, 16, 16, $n_f$     | 12,288    |\n",
    "| conv_2        |  6  |  6  |     $n_f$      |$2 \\times n_f$|    2   | VALID   | ?, 6, 6, $2 \\times n_f$ | 294,912 |\n",
    "| conv_3        |  5  |  5  | $2 \\times n_f$ |$2 \\times n_f$|    1   | VALID   | ?, 2, 2, $2 \\times n_f$ | 409, 600  |\n",
    "| fc_out        |  1  |  1  | $8 \\times n_f$ |      10      |    1   | n/a     | ?, 10 | 5,120 |\n",
    "| Total         |    |    |   |           |       |      |  | 721,920 |\n",
    "\n",
    "### Notes on padding\n",
    "\n",
    "First, you will notice in the code below that `strides=[1, X, X, 1]`. We generally stride by one unit along each\n",
    "input channel and for each input, which is why `strides[0]` and `strides[3]` are usually 1. We take the value in the \"Stride\" column as `X` in the length 4 strides vector.\n",
    "\n",
    "#### `SAME` padding:\n",
    "\n",
    "For `conv_1`:\n",
    "\n",
    "-    `out_height = ceil(float(in_height) / float(strides[1]))` = `ceil(float(32) / float(2))` = `ceil(16)` = $16$\n",
    "-    `out_width  = ceil(float(in_width) / float(strides[2]))` = \" = $16$\n",
    "\n",
    "Now, given that we know the output dimensionality has `(height, width)` = ($16$,$16$), how much padding was used?\n",
    "\n",
    "$$ ceil( \\frac{n_i + p_i - k + 1}{s} )  = n_o $$\n",
    "\n",
    "In general, ceil( $\\frac{x}{a}$ ) = $b$ with $a > 0$ means $b - 1 < \\frac{x}{a} \\leq b$, the smallest integer that satisfies this is $x = a(b-1) + 1$.\n",
    "\n",
    "$$ n_i + p_i - k + 1 = s (n_o - 1) + 1 $$\n",
    "\n",
    "$$ p_i = s (n_o - 1) + k - n_i $$\n",
    "\n",
    "$$ p_i = 2 (16 - 1) + 8 - 32 = 30 + 8 - 32 = 6 $$\n",
    "\n",
    "Therefore `conv_1` output shape is `[?, 16, 16, nf]`\n",
    "\n",
    "#### `VALID` padding:\n",
    "\n",
    "For `conv_2`:\n",
    "\n",
    "- `out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))` = `ceil((16 - 6 + 1) / 2))` = `ceil(5.5)` = $6$\n",
    "- `out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))` = \" = $6$\n",
    "\n",
    "Therefore `conv_2` output shape is `[?, 6, 6, 2(nf)]` and no padding is used.\n",
    "\n",
    "For `conv_3`:\n",
    "\n",
    "- `ceil((6 - 5 + 1) / 1))` = `ceil(2)` = $2$\n",
    "\n",
    "Therefore `conv_3` output shape is `[?, 2, 2, 2(nf)]` and no padding is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model\n",
    "\n",
    "Okay, that was lots of fun arithmetic. Now what does this look like in actual TensorFlow code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet:\n",
    "    \n",
    "    def __init__(self, x, nb_filters, use_batch_norm, phase, reuse):\n",
    "        self.__dict__.update(locals())\n",
    "        self.convolutional_layers(use_batch_norm, phase)\n",
    "        # calculate the number of parameters to be learned in our model\n",
    "        self.nb_params = np.sum([np.prod(v.shape) for v in tf.trainable_variables()])\n",
    "        print(\"Created instance of CNN model with %d parameters\" % self.nb_params)\n",
    "    \n",
    "    def initialize_kernel(self, shape, stddev=0.1):\n",
    "        init = tf.truncated_normal(shape, stddev=stddev, dtype=tf.float32)\n",
    "        init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=(0, 1, 2)))\n",
    "        return tf.Variable(init)\n",
    "    \n",
    "    def get_kernel(self, shape, stddev=0.1):\n",
    "        init = tf.truncated_normal(shape, stddev=stddev, dtype=tf.float32)\n",
    "        init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=(0, 1, 2)))\n",
    "        return tf.get_variable(\"k\", initializer=init)\n",
    "    \n",
    "    def initialize_weight(self, shape, stddev=0.1):\n",
    "        init = tf.truncated_normal(shape, stddev=stddev, dtype=tf.float32)\n",
    "        init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=0, keep_dims=True))\n",
    "        return tf.Variable(init)\n",
    "    \n",
    "    def get_weight(self, shape, stddev=0.1):\n",
    "        init = tf.truncated_normal(shape, stddev=stddev, dtype=tf.float32)\n",
    "        init = init / tf.sqrt(1e-7 + tf.reduce_sum(tf.square(init), axis=0, keep_dims=True))\n",
    "        return tf.get_variable(\"w\", initializer=init)\n",
    "    \n",
    "    def bias_variable(self, shape):\n",
    "        init = tf.constant(0, shape=shape)\n",
    "        return tf.Variable(init)\n",
    "    \n",
    "    def conv2d(self, x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "    def max_pool_2x2(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                              strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "    def convolutional_layers(self, use_batch_norm, phase):\n",
    "\n",
    "        pad_k = tf.constant([[1, 1], [1, 1], [0, 0]])\n",
    "        pad_a = tf.constant([[0, 0], [1, 1], [1, 1]])\n",
    "\n",
    "        with tf.name_scope('conv_1') as scope:\n",
    "\n",
    "            k_sz = 8 # the square kernel size (e.g 8x8)\n",
    "            \n",
    "            #W_conv1 = self.initialize_kernel([k_sz, k_sz, int(self.x.shape[3]), self.nb_filters])\n",
    "            '''\n",
    "            Try un-commmenting the above line in all layers and observing the number\n",
    "            of parameters change everytime you run the below cell titled\n",
    "            \"Instantiate the CNN model\". If we don't explicitly tell TensorFlow to re-use \n",
    "            variables, additional copies of the graph will be created, blowing up the \n",
    "            number of parameters. Reusing variables is accomplished by creating them under\n",
    "            a tf.variable_scope, and using tf.get_variable rather than tf.Variable.\n",
    "            If you want to force a new variable to be created everytime, you can\n",
    "            set reuse=False.\n",
    "            '''\n",
    "            with tf.variable_scope('conv_1_init', reuse=self.reuse):\n",
    "                W_conv1 = self.get_kernel([k_sz, k_sz, int(self.x.shape[3]), self.nb_filters])\n",
    "                \n",
    "            '''\n",
    "            for logging to Tensorboard \"Images\" tab. \n",
    "            This is a bit of a hack to combine all 8x8 convolution\n",
    "            filters into one image.\n",
    "            '''\n",
    "            W1_c = tf.split(W_conv1, self.nb_filters, 3)  # nb_filters x [8, 8, 3, 1]\n",
    "            for i in range(self.nb_filters):\n",
    "                W1_c[i] = tf.pad(tf.reshape(\n",
    "                    W1_c[i], [k_sz, k_sz, int(self.x.shape[3])]), pad_k, \"CONSTANT\")\n",
    "            W1_row0 = tf.concat(W1_c[0:8], 0)      # [80, 10, 3, 1]\n",
    "            W1_row1 = tf.concat(W1_c[8:16], 0)     # [80, 10, 3, 1]\n",
    "            W1_row2 = tf.concat(W1_c[16:24], 0)    # [80, 10, 3, 1]\n",
    "            W1_row3 = tf.concat(W1_c[24:32], 0)    # [80, 10, 3, 1]\n",
    "            W1_row4 = tf.concat(W1_c[32:40], 0)    # [80, 10, 3, 1]\n",
    "            W1_row5 = tf.concat(W1_c[40:48], 0)    # [80, 10, 3, 1]\n",
    "            W1_row6 = tf.concat(W1_c[48:56], 0)    # [80, 10, 3, 1]\n",
    "            W1_row7 = tf.concat(W1_c[56:64], 0)    # [80, 10, 3, 1]\n",
    "            W1_d = tf.concat([W1_row0, W1_row1, W1_row2, W1_row3, W1_row4,\n",
    "                              W1_row5, W1_row6, W1_row7], 1)  # [80, 80, 3, 1]\n",
    "            W1_e = tf.reshape(W1_d, [1, 80, 80, int(self.x.shape[3])])\n",
    "            \n",
    "            # Create the actual summary to appear in Tensorboard\n",
    "            tf.summary.image(\"k1\", W1_e, 1)\n",
    "\n",
    "            # Create tensors for L1 and L2 weight decay\n",
    "            self.W_conv1_p = tf.nn.l2_loss(W_conv1)\n",
    "            self.W_conv1_l1 = tf.reduce_mean(tf.abs(W_conv1))\n",
    "            \n",
    "            h_conv1 = tf.nn.relu(tf.nn.conv2d(\n",
    "                self.x, W_conv1, strides=[1, 2, 2, 1], padding='SAME'))\n",
    "\n",
    "            a1_u, a1_var = tf.nn.moments(\n",
    "                tf.abs(h_conv1), axes=[0], keep_dims=False)\n",
    "\n",
    "            tf.summary.histogram(name='h_conv1_summ', values=h_conv1)\n",
    "            tf.summary.histogram(name='W_conv1_summ', values=W_conv1)\n",
    "            tf.summary.scalar(\"activation_mean\", tf.reduce_mean(a1_u))\n",
    "            tf.summary.scalar(\"activation_variance\", tf.reduce_mean(a1_var))\n",
    "\n",
    "        with tf.name_scope('conv_2') as scope:\n",
    "\n",
    "            k_sz = 6 # the square kernel size\n",
    "            in_ch = self.nb_filters\n",
    "            out_ch = self.nb_filters * 2\n",
    "            \n",
    "            #self.W_conv2 = self.initialize_kernel([k_sz, k_sz, in_ch, out_ch])\n",
    "            with tf.variable_scope('conv_2_init', reuse=self.reuse):\n",
    "                self.W_conv2 = self.get_kernel([k_sz, k_sz, in_ch, out_ch])\n",
    "            \n",
    "            # Create tensors for L1 and L2 weight decay\n",
    "            self.W_conv2_p = tf.nn.l2_loss(self.W_conv2)\n",
    "            self.W_conv2_l1 = tf.reduce_mean(tf.abs(self.W_conv2))\n",
    "\n",
    "            if self.use_batch_norm:\n",
    "                # see https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm\n",
    "                # for full list of default settings.\n",
    "                with tf.variable_scope('conv_2_bn', reuse=self.reuse):\n",
    "                    h_conv1 = tf.contrib.layers.batch_norm(h_conv1, is_training=phase)\n",
    "\n",
    "            W2_c = tf.split(self.W_conv2, self.nb_filters * 2,\n",
    "                            3)  # f_out x [6, 6, f_in, 1]\n",
    "            for i in range(self.nb_filters):\n",
    "                W2_c[i] = tf.pad(tf.reshape(\n",
    "                    W2_c[i], [k_sz, k_sz, self.nb_filters]), pad_k, \"CONSTANT\")\n",
    "            W2_row0 = tf.concat(W2_c[0:8], 0)      # [64, 8, f_in, 1]\n",
    "            W2_row1 = tf.concat(W2_c[8:16], 0)     # [64, 8, f_in, 1]\n",
    "            W2_row2 = tf.concat(W2_c[16:24], 0)    # [64, 8, f_in, 1]\n",
    "            W2_row3 = tf.concat(W2_c[24:32], 0)    # [64, 8, f_in, 1]\n",
    "            W2_row4 = tf.concat(W2_c[32:40], 0)    # [64, 8, f_in, 1]\n",
    "            W2_row5 = tf.concat(W2_c[40:48], 0)    # [64, 8, f_in, 1]\n",
    "            W2_row6 = tf.concat(W2_c[48:56], 0)    # [64, 8, f_in, 1]\n",
    "            W2_row7 = tf.concat(W2_c[56:64], 0)    # [64, 8, f_in, 1]\n",
    "            W2_d = tf.concat([W2_row0, W2_row1, W2_row2, W2_row3, W2_row4,\n",
    "                              W2_row5, W2_row6, W2_row7], 1)  # [64, 64, 3, 1]\n",
    "            W2_e = tf.reshape(W2_d, [1, 64, 64, self.nb_filters])\n",
    "            W2_f = tf.split(W2_e, self.nb_filters, 3)  # 64 x [1, 64, 64, 1]\n",
    "            W2_g = tf.concat(W2_f[0:self.nb_filters], 0)\n",
    "            \n",
    "            # Create the summary to appear in Tensorboard\n",
    "            tf.summary.image(\"k2\", W2_g, 4)\n",
    "\n",
    "            h_conv2 = tf.nn.relu(tf.nn.conv2d(\n",
    "                h_conv1, self.W_conv2, strides=[1, 2, 2, 1], padding='VALID'))\n",
    "\n",
    "            a2_u, a2_var = tf.nn.moments(\n",
    "                tf.abs(h_conv2), axes=[0], keep_dims=False)\n",
    "\n",
    "            tf.summary.histogram(name='W_conv2_summ', values=self.W_conv2)\n",
    "            tf.summary.histogram(name='h_conv2_summ', values=h_conv2)\n",
    "            tf.summary.scalar(\"activation_mean\", tf.reduce_mean(a2_u))\n",
    "            tf.summary.scalar(\"activation_variance\", tf.reduce_mean(a2_var))\n",
    "            \n",
    "        with tf.name_scope('conv_3') as scope:\n",
    "        \n",
    "            k_sz = 5 # the square kernel size\n",
    "            in_ch = self.nb_filters * 2\n",
    "            out_ch = self.nb_filters * 2\n",
    "            \n",
    "            #self.W_conv3 = self.initialize_kernel([k_sz, k_sz, in_ch, out_ch])\n",
    "            with tf.variable_scope('conv_3_init', reuse=self.reuse):\n",
    "                self.W_conv3 = self.get_kernel([k_sz, k_sz, in_ch, out_ch])\n",
    "            \n",
    "            # weight decay\n",
    "            self.W_conv3_p = tf.nn.l2_loss(self.W_conv3)\n",
    "            self.W_conv3_l1 = tf.reduce_mean(tf.abs(self.W_conv3))\n",
    "    \n",
    "            if self.use_batch_norm:\n",
    "                with tf.variable_scope('conv_3_bn', reuse=self.reuse):\n",
    "                    h_conv2 = tf.contrib.layers.batch_norm(h_conv2, is_training=phase)\n",
    "\n",
    "            h_conv3 = tf.nn.relu(tf.nn.conv2d(\n",
    "                h_conv2, self.W_conv3, strides=[1, 1, 1, 1], padding='VALID'))\n",
    "\n",
    "            a3_u, a3_var = tf.nn.moments(\n",
    "                tf.abs(h_conv3), axes=[0], keep_dims=False)\n",
    "\n",
    "            tf.summary.histogram(name='W_conv3_summ', values=self.W_conv3)\n",
    "            tf.summary.histogram(name='h_conv3_summ', values=h_conv3)\n",
    "            tf.summary.scalar(\"activation_mean\", tf.reduce_mean(a3_u))\n",
    "            tf.summary.scalar(\"activation_variance\", tf.reduce_mean(a3_var))\n",
    "            \n",
    "        with tf.name_scope('fc_out') as scope:\n",
    "\n",
    "            nb_classes = 10\n",
    "            in_sz = self.nb_filters * 8\n",
    "            \n",
    "            #W_fcout = self.initialize_weight([in_sz, nb_classes])\n",
    "            with tf.variable_scope('fc_out_init', reuse=self.reuse):\n",
    "                W_fcout = self.get_weight([in_sz, nb_classes])\n",
    "            \n",
    "            # weight decay\n",
    "            self.W_fcout_p = tf.nn.l2_loss(W_fcout)\n",
    "            self.W_fcout_l1 = tf.reduce_mean(tf.abs(W_fcout))\n",
    "\n",
    "            h_conv3_flat = tf.reshape(h_conv3, [-1, in_sz])\n",
    "            \n",
    "            # tensor equivalent of numpy.dot()\n",
    "            self.output = tf.matmul(h_conv3_flat, W_fcout) \n",
    "\n",
    "            y_u, y_var = tf.nn.moments(\n",
    "                tf.abs(self.output), axes=[0], keep_dims=False)\n",
    "\n",
    "            norm_out = tf.norm(W_fcout)\n",
    "            \n",
    "            tf.summary.histogram(name='output_summ', values=self.output)\n",
    "            tf.summary.scalar(\"norm_out\", norm_out)\n",
    "            tf.summary.scalar(\"logits_mean\", tf.reduce_mean(y_u))\n",
    "            tf.summary.scalar(\"logits_var\", tf.reduce_mean(y_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method for loading and preprocessing the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cifar10():\n",
    "    \"\"\"\n",
    "    Preprocess CIFAR-10 dataset\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # These values are specific to CIFAR-10\n",
    "    img_rows = 32\n",
    "    img_cols = 32\n",
    "    nb_classes = 10\n",
    "\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = data_cifar10()\n",
    "__, img_rows, img_cols, channels = train_x.shape\n",
    "__, nb_classes = train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some variables and placeholders\n",
    "Can think of a feedforward neural network as a directed acyclic graph (DAG) G(V, E) where V are vertices and E edges. Input `x_` and output `y_` nodes correspond to vertices, with weights along the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to keep track of how many steps we've trained our model for\n",
    "tf.reset_default_graph()\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "dtype = tf.float32\n",
    "x_ = tf.placeholder(dtype, shape=(None, img_rows, img_cols, channels))\n",
    "y_ = tf.placeholder(dtype, shape=(None, nb_classes))\n",
    "\n",
    "# This is for batch normalization. True means training mode, False means testing mode.\n",
    "phase = tf.placeholder_with_default(True, shape=(), name='phase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_save_path(root_path, batch_size, nb_filters, learning_rate, epochs):\n",
    "    \n",
    "    model_path = os.path.join(root_path, 'k_' + str(nb_filters))\n",
    "    model_path = os.path.join(model_path, 'bs_' + str(batch_size))\n",
    "    model_path = os.path.join(model_path, 'lr_%1.e' % learning_rate)\n",
    "    model_path = os.path.join(model_path, 'ep_' + str(epochs))\n",
    "    '''\n",
    "    optionally create this folder if it does not already exist,\n",
    "    otherwise, increment the subfolder number\n",
    "    '''\n",
    "    model_path = create_dir_if_not_exists(model_path)\n",
    "\n",
    "    return model_path\n",
    "\n",
    "\n",
    "def create_dir_if_not_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        path += '/1'\n",
    "        os.makedirs(path)\n",
    "    else:\n",
    "        digits = []\n",
    "        sub_dirs = next(os.walk(path))[1]\n",
    "        [digits.append(s) for s in sub_dirs if s.isnumeric()]\n",
    "        if len(digits) > 0:\n",
    "            sub = str(np.max(np.asarray(sub_dirs).astype('uint8')) + 1)        \n",
    "        else:\n",
    "            sub = '1'\n",
    "        path = os.path.join(path, sub)\n",
    "        os.makedirs(path)\n",
    "    print('Logging to:%s' % path)\n",
    "    return path\n",
    "\n",
    "\n",
    "def batch_indices(batch_nb, data_length, batch_size):\n",
    "    \"\"\"\n",
    "    This helper function computes a batch start and end index\n",
    "    :param batch_nb: the batch number\n",
    "    :param data_length: the total length of the data being parsed by batches\n",
    "    :param batch_size: the number of inputs in each batch\n",
    "    :return: pair of (start, end) indices\n",
    "    \"\"\"\n",
    "    # Batch start and end index\n",
    "    start = int(batch_nb * batch_size)\n",
    "    end = int((batch_nb + 1) * batch_size)\n",
    "\n",
    "    # When there are not enough inputs left, we reuse some to complete the\n",
    "    # batch\n",
    "    if end > data_length:\n",
    "        shift = end - data_length\n",
    "        start -= shift\n",
    "        end -= shift\n",
    "\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = 1e-3\n",
    "l1_reg = 1e-3\n",
    "nb_epochs = 25\n",
    "nb_filters = 64\n",
    "batch_size = 128 # normally use 128\n",
    "learning_rate = 1e-3\n",
    "batch_norm = True\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to:/scratch/ssd/logs/cifar10/k_64/bs_128/lr_1e-03/ep_25/3\n"
     ]
    }
   ],
   "source": [
    "model_path = '/scratch/ssd/logs/cifar10'\n",
    "\n",
    "# assume we're going to train from scratch, and not log checkpoints\n",
    "save = False\n",
    "train_from_scratch = True\n",
    "\n",
    "if model_path is not None:\n",
    "    if os.path.exists(model_path):\n",
    "        # check for existing model in immediate subfolder\n",
    "        if any(f.endswith('.meta') for f in os.listdir(model_path)):\n",
    "            train_from_scratch = False\n",
    "        else:\n",
    "            save = True\n",
    "            model_path = build_model_save_path(\n",
    "                model_path, batch_size, nb_filters, learning_rate, nb_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the CNN model\n",
    "\n",
    "With the default settings and when reusing variables, we should get $721,920$ parameters \n",
    "if `batch_norm=False`, and $721,920 + 192 = 722,112$ parameters if `batch_norm=True`.\n",
    "Options for the reuse argument are `False`, `True`, and `tf.AUTO_REUSE`. The call will\n",
    "fail if you set `reuse=True` the first time you run the below cell, since the variables\n",
    "have not yet been created. The call will fail on subsequent calls if you set\n",
    "`reuse=False`, since variables with the same name already exist. This flow generally\n",
    "prevents you from making silly mistakes and enforces the desirable behaviour. `tf.AUTO_REUSE`\n",
    "will always do the right thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created instance of CNN model with 722112 parameters\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(x_, nb_filters, batch_norm, phase, reuse=tf.AUTO_REUSE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = cnn.output\n",
    "\n",
    "total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=y_, logits=logits))\n",
    "\n",
    "# if you just want the model predictions, use the following:\n",
    "# preds = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add weight decay to loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss += l2_reg * (cnn.W_conv1_p + cnn.W_conv2_p +\n",
    "                        cnn.W_conv3_p + cnn.W_fcout_p)\n",
    "\n",
    "total_loss += l1_reg * (cnn.W_conv1_l1 + cnn.W_conv2_l1 +\n",
    "                        cnn.W_conv3_l1 + cnn.W_fcout_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training op, and batch normalization if applicable\n",
    "\n",
    "If using batch_norm, the moving mean and moving variance need to be updated on each step. We add them as a dependency of the training step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if batch_norm:\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        # ensures that we execute the update_ops before performing the train_op\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "                    total_loss, global_step, learning_rate=learning_rate, optimizer='Adam',  # SGD\n",
    "                    summaries=[\"gradients\"])\n",
    "else:\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "                total_loss, global_step, learning_rate=learning_rate, optimizer='Adam',\n",
    "                summaries=[\"gradients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "create tensors that will automatically compute the number of \n",
    "correct predictions and accuracy in a sample\n",
    "'''\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startup time was 0.1092\n"
     ]
    }
   ],
   "source": [
    "# sess = tf.Session()\n",
    "start_time = time.time()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "d = float(time.time() - start_time)\n",
    "print(\"Startup time was %.4f\" % d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup summary writer\n",
    "if save:\n",
    "    summary_writer = tf.summary.FileWriter(model_path, sess.graph)\n",
    "    tf.summary.scalar(\n",
    "                \"stats/train_loss\", total_loss)\n",
    "    tf.summary.scalar(\"stats/train_accuracy\", accuracy)\n",
    "    \n",
    "    # create one op that will run all summaries\n",
    "    merge_op = tf.summary.merge_all()\n",
    "    checkpoint_path = os.path.join(model_path, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sess, tensor, x, y, x_np, y_np, feed=None):\n",
    "    feed_dict = {x: x_np, y: y_np, phase: False}\n",
    "    if feed is not None:\n",
    "        feed_dict.update(feed)\n",
    "    return sess.run(tensor, feed_dict)\n",
    "\n",
    "def evaluate_model(sess, accuracy, x, y, test_x, test_y, batch_size):\n",
    "    \"\"\"\n",
    "    This helper function evaluates a model on one pass through\n",
    "    the test set\n",
    "    :param accuracy: the tensor that computes accuracy\n",
    "    :param x: input placeholder\n",
    "    :param y: output placeholder\n",
    "    :param test_x: the test examples\n",
    "    :param test_y: the test labels\n",
    "    :param batch_size: batch size to use when evaluating\n",
    "    :return: accuracy on the test set\n",
    "    \"\"\"\n",
    "    nb_test_examples = test_x.shape[0]\n",
    "    nb_test_batches = int(\n",
    "        np.ceil(float(nb_test_examples) / batch_size))\n",
    "    # print('nb_test_batches=%d' % nb_test_batches)\n",
    "    assert nb_test_batches * batch_size >= nb_test_examples\n",
    "\n",
    "    tot_accuracy = 0.0\n",
    "    for e, test_batch in enumerate(range(nb_test_batches)):\n",
    "        # Must not use the `batch_indices` function here, because it\n",
    "        # repeats some examples.\n",
    "        # It's acceptable to repeat during training, but not eval.\n",
    "        start = test_batch * batch_size\n",
    "        end = min(nb_test_examples, start + batch_size)\n",
    "        cur_batch_size = end - start\n",
    "        batch_xs = test_x[start:end]\n",
    "        batch_ys = test_y[start:end]\n",
    "        cur_acc = evaluate(sess, accuracy, x,\n",
    "                           y_, batch_xs, batch_ys)\n",
    "        tot_accuracy += (cur_batch_size * cur_acc)\n",
    "    tot_accuracy /= nb_test_examples\n",
    "    return tot_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_training_batches=391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:40<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss=1.3003, test_acc=0.3096 (1152.4 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:36<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss=1.3257, test_acc=0.1122 (2192.8 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:34<00:00, 11.47it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss=1.1649, test_acc=0.1106 (1341.8 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:33<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss=0.9689, test_acc=0.1693 (1816.4 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:33<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss=0.8631, test_acc=0.1294 (1903.0 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:32<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss=0.6612, test_acc=0.3620 (1898.8 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:31<00:00, 12.27it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, loss=0.7536, test_acc=0.3562 (1651.4 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:32<00:00, 11.97it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, loss=0.6523, test_acc=0.3286 (1899.4 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:32<00:00, 11.97it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, loss=0.7368, test_acc=0.5172 (2152.1 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:32<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, loss=0.7368, test_acc=0.4605 (1019.9 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:32<00:00, 12.18it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss=0.7543, test_acc=0.5677 (1708.7 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:32<00:00, 12.22it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, loss=0.5681, test_acc=0.6115 (1464.8 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:32<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, loss=0.6373, test_acc=0.6093 (1994.3 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:31<00:00, 12.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, loss=0.5764, test_acc=0.6548 (1292.7 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:32<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, loss=0.6246, test_acc=0.6449 (1774.4 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:31<00:00, 12.43it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, loss=0.6794, test_acc=0.6147 (1647.5 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:32<00:00, 12.19it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, loss=0.5701, test_acc=0.6736 (1247.2 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:32<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, loss=0.5968, test_acc=0.6467 (1685.9 ex/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 165/391 [00:13<00:18, 12.19it/s]"
     ]
    }
   ],
   "source": [
    "if train_from_scratch:\n",
    "    step = 0\n",
    "    init_step = 0\n",
    "    max_acc = 0\n",
    "    \n",
    "    # Compute number of training batches\n",
    "    nb_training_examples = train_x.shape[0]\n",
    "    nb_batches = int(\n",
    "    np.ceil(float(nb_training_examples) / batch_size))\n",
    "    print('nb_training_batches=%d' % nb_batches)\n",
    "    assert nb_batches * batch_size >= nb_training_examples\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "\n",
    "        # Indices to shuffle training set\n",
    "        index_shuf = np.arange(nb_training_examples)\n",
    "        np.random.shuffle(index_shuf)\n",
    "\n",
    "        for batch in tqdm(range(nb_batches)):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            step = init_step + (epoch * nb_batches + batch)\n",
    "\n",
    "            # Compute batch start and end indices\n",
    "            start, end = batch_indices(\n",
    "                batch, nb_training_examples, batch_size)\n",
    "\n",
    "            batch_xs = train_x[index_shuf[start:end]]\n",
    "            batch_ys = train_y[index_shuf[start:end]]\n",
    "\n",
    "            __, loss_val, summ = sess.run([train_op, total_loss, merge_op], feed_dict={\n",
    "                x_: batch_xs, y_: batch_ys})\n",
    "            duration = time.time() - start_time\n",
    "            summary_writer.add_summary(summ, global_step=step)\n",
    "        summary_writer.flush()\n",
    "\n",
    "        # Init result var\n",
    "        tot_accuracy = evaluate_model(\n",
    "            sess, accuracy, x_, y_, test_x, test_y, batch_size)       \n",
    "\n",
    "        print(\"epoch %d, loss=%.4f, test_acc=%.4f (%.1f ex/s)\" %\n",
    "              (epoch, loss_val, tot_accuracy, float(batch_size / duration)))\n",
    "\n",
    "        if model_path:\n",
    "            saver.save(sess, checkpoint_path, global_step=step)\n",
    "        step += 1\n",
    "    # close the TensorFlow client session\n",
    "    tf.reset_default_graph()\n",
    "    sess.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
